{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab7-for-deeplearn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "jTEzoMx6CasV"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nahilsobh/BBox-Label-Tool/blob/master/Colab7_for_deeplearn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jTEzoMx6CasV"
      },
      "cell_type": "markdown",
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IhmPj1VVCfWb",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YHK6DyunSbs4"
      },
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction and Transfer learning.\n",
        "\n",
        "To this point you built a Convolutional Neural Network that classified Cats v Dogs with a decent level of accuracy. You explored some techniques to improve it including using Data Augmentation, Dropouts and more. \n",
        "\n",
        "This involved you building the model from scratch -- but what if you could use an existing model, and the features that were learned from that model? In particular, models that have been trained on enormous data sets with huge amounts of computing power -- things that may not be available to you. \n",
        "\n",
        "This is possible with transfer learning. Let's take a look..."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "dI5rmt4UBwXs"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Extraction from a Pretrained Model\n",
        "\n",
        "One thing that is commonly done in computer vision is to take a model trained on a very large dataset, run it on your own, smaller dataset, and extract the intermediate representations (features) that the model generates. These representations are frequently informative for your own computer vision task, even though the task may be quite different from the problem that the original model was trained on. This versatility and repurposability of convnets is one of the most interesting aspects of deep learning.\n",
        "\n",
        "In our case, we will use the [Inception V3 model](https://arxiv.org/abs/1512.00567) developed at Google, and pre-trained on [ImageNet](http://image-net.org/), a large dataset of web images (1.4M images and 1000 classes). This is a powerful model; let's see what the features that it has learned can do for our cat vs. dog problem.\n",
        "\n",
        "First, we need to pick which intermediate layer of Inception V3 we will use for feature extraction. A common practice is to use the output of the very last layer before the `Flatten` operation, the so-called \"bottleneck layer.\" The reasoning here is that the following fully connected layers will be too specialized for the task the network was trained on, and thus the features learned by these layers won't be very useful for a new task. The bottleneck features, however, retain much generality.\n",
        "\n",
        "Let's instantiate an Inception V3 model preloaded with weights trained on ImageNet:\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VaXLMtYiF0t9"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's download the weights:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KMrbllgAFipZ",
        "outputId": "9b328d36-7ed6-48b5-addc-ab5cdfb92cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-09 07:01:33--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  69.2MB/s    in 1.2s    \n",
            "\n",
            "2019-02-09 07:01:34 (69.2 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UnRiGBfOF8rq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "39460df7-ada6-4a38-e17d-c725e68ea14b"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3( input_shape = (150, 150, 3), \n",
        "                                 include_top = False        , \n",
        "                                 weights     = None\n",
        "                               )\n",
        "\n",
        "pre_trained_model.load_weights( local_weights_file )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "IcYZPBS3bTAj"
      },
      "cell_type": "markdown",
      "source": [
        "By specifying the `include_top=False` argument, we load a network that doesn't include the classification layers at the top—ideal for feature extraction."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "CFxrqTuJee5m"
      },
      "cell_type": "markdown",
      "source": [
        "Let's make the model non-trainable, since we will only use it for feature extraction; we won't update the weights of the pretrained model during training."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "a38rB3lyedcB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "XGBGDiOAepnO"
      },
      "cell_type": "markdown",
      "source": [
        "Explore the design of this model by calling \n",
        "\n",
        "\n",
        "```\n",
        "pre_trained_model.summary()\n",
        "```\n",
        "\n",
        "You'll see it's a a bigger and far more detailed model that you've been buiding, but that's to be expected for 1.4m images in 1000 different classes! If you start at the bottom and work your way up, you'll see that the images have convolved down to 3x3 feature maps which are really small. Keep moving up, and the last layer that you'll see that is bigger than that is called 'mixed7'. Let's use that one (it's 7x7) so, contains over 5x the information than the 3x3 ones (49 pixels as opposed to 9)\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jTVNFhD5xoha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pre_trained_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8NVO3GwLxv2z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To get the details on mixed7, you can pull it out of the model with get_layer(), and then inspect its output_shape property:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Cj4rXshqbQlS",
        "outputId": "90ca7f5e-9d71-4f37-9a91-0ff30c3ab7f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "\n",
        "print('last layer output shape: ', \n",
        "       last_layer.output_shape   )\n",
        "\n",
        "last_output = last_layer.output"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "XxHk6XQLeUWh"
      },
      "cell_type": "markdown",
      "source": [
        "So now we can build a model that uses that layer as its input. \n",
        "\n",
        "This is very similar to what you've seen already, but instead of input layer being shaped like the data, we're making the 'mixed7' from the previous section (which we called last_output) the top of this model.\n",
        "\n",
        "After that we'll just do the standard Dense layers from a DNN, with an output layer having 1 neuron, activated by a sigmoid that will trend to 0 for one of the classes, and 1 for the other. (It's a binary classification of Cats v Dogs after all)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "31837fc1-767e-4de4-e0df-9e857f8efb3c"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "\n",
        "x = layers.Flatten(                          )(last_output) # Flatten the output layer to 1 dimension\n",
        "x = layers.Dense  (1024, activation='relu'   )(x)           # Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dropout(0.2                       )(x)           # Add a dropout rate of 0.2\n",
        "x = layers.Dense  (1,    activation='sigmoid')(x)           # Add a final sigmoid layer for classification\n",
        "\n",
        "# -------------------------------\n",
        "# Configure and compile the model\n",
        "# -------------------------------\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile( optimizer =  RMSprop(lr=0.0001)   ,\n",
        "               loss      =  'binary_crossentropy',\n",
        "               metrics   = ['acc']\n",
        "             )\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_6ECjowwV5Ug"
      },
      "cell_type": "markdown",
      "source": [
        "For examples and data preprocessing, let's use the same files and `train_generator` as we did in Exercise 2."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Cl-IqOTjZVw_"
      },
      "cell_type": "markdown",
      "source": [
        "**NOTE:** The 2,000 images used in this exercise are excerpted from the [\"Dogs vs. Cats\" dataset](https://www.kaggle.com/c/dogs-vs-cats/data) available on Kaggle, which contains 25,000 images. Here, we use a subset of the full dataset to decrease training time for educational purposes."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "outputId": "79673ab8-015a-45d3-93b9-9bec15e41779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "# ----------------\n",
        "!wget --no-check-certificate \\\n",
        "        https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "       -O /tmp/cats_and_dogs_filtered.zip"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-09 07:01:49--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 2607:f8b0:400e:c09::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M   149MB/s    in 0.4s    \n",
            "\n",
            "2019-02-09 07:01:49 (149 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Fl9XXARuV_eg",
        "outputId": "22daf5ad-923e-486a-c7a3-0ac5f84d1667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# ----------------\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
        "\n",
        "zip_ref   = zipfile.ZipFile(local_zip, 'r')\n",
        "\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define our example directories and files\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "\n",
        "train_dir      = os.path.join( base_dir, 'train'     )\n",
        "validation_dir = os.path.join( base_dir, 'validation')\n",
        "\n",
        "\n",
        "train_cats_dir      = os.path.join(train_dir,      'cats') # Directory with our training cat pictures\n",
        "train_dogs_dir      = os.path.join(train_dir,      'dogs') # Directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
        "\n",
        "train_cat_fnames    = os.listdir(train_cats_dir)\n",
        "train_dog_fnames    = os.listdir(train_dogs_dir)\n",
        "\n",
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator( rescale            = 1./255.,\n",
        "                                    rotation_range     = 40     ,\n",
        "                                    width_shift_range  = 0.2    ,\n",
        "                                    height_shift_range = 0.2    ,\n",
        "                                    shear_range        = 0.2    ,\n",
        "                                    zoom_range         = 0.2    ,\n",
        "                                    horizontal_flip    = True\n",
        "                                  )\n",
        "#-----\n",
        "# Note that the validation data should not be augmented!\n",
        "#-----\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "\n",
        "# --------------------\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "# --------------------\n",
        "train_generator      = train_datagen.flow_from_directory( train_dir               , # directory for training images\n",
        "                                                          batch_size  = 20        ,\n",
        "                                                          class_mode  = 'binary'  , # binary labels to use with binary_crossentropy loss\n",
        "                                                          target_size = (150, 150)  # All images are resized to 150x150     \n",
        "                                                        )     \n",
        "# --------------------\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "# --------------------\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir          ,\n",
        "                                                          batch_size  = 20        ,\n",
        "                                                          class_mode  = 'binary'  , \n",
        "                                                          target_size = (150, 150) \n",
        "                                                        )"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qEC1AL7iVRLz"
      },
      "cell_type": "markdown",
      "source": [
        "Finally, let's train the model using the features we extracted. We'll train on all 2000 images available, for 2 epochs, and validate on all 1,000 test images."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "outputId": "b1015538-d679-4501-b50a-371427f3bfa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator( train_generator                         ,\n",
        "                               validation_data  = validation_generator ,\n",
        "                               steps_per_epoch  = 100                  ,  # 2000 images = batch_size * steps\n",
        "                               epochs           =   2                  ,\n",
        "                               validation_steps =  50                  ,  # 1000 images = batch_size * steps\n",
        "                               verbose          =   2                     # Verbosity mode (one line per epoch)\n",
        "                             )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/2\n",
            "50/50 [==============================] - 7s 149ms/step - loss: 0.1582 - acc: 0.9480\n",
            " - 32s - loss: 0.4884 - acc: 0.7715 - val_loss: 0.1582 - val_acc: 0.9480\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 0.2874 - acc: 0.9280\n",
            " - 27s - loss: 0.3643 - acc: 0.8375 - val_loss: 0.2874 - val_acc: 0.9280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lRjyAkE62aOG"
      },
      "cell_type": "markdown",
      "source": [
        "Check out the validation set accuracy -- it's probably in the mid-high 90s, after only 1 or 2 epochs -- far better performance than the previous models that were trained from scratch, and you got there quicker!\n",
        "\n",
        "#Exercises\n",
        "1. Go back to the pre-trained model summary, and find other layers to take the output from -- maybe mixed8 or something earlier in the model. Explore the impact this has by setting it as the input for your new model.\n",
        "\n",
        "2. Explore the impact of changing the image augmentation settings in train_datagen: Can you improve the model performance\n",
        "\n",
        "3. In the previous lesson you did a multi-class classifier with the flowers dataset. See if you can create a model that improves its performance using the transfer learning techniques you've explored here!\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tt15y6IS2pBo"
      },
      "cell_type": "markdown",
      "source": [
        "## Further Improving Accuracy with Fine-Tuning\n",
        "\n",
        "In our feature-extraction experiment, we only tried adding two classification layers on top of an Inception V3 layer. The weights of the pretrained network were not updated during training. One way to increase performance even further is to \"fine-tune\" the weights of the top layers of the pretrained model alongside the training of the top-level classifier. A couple of important notes on fine-tuning:\n",
        "\n",
        "- **Fine-tuning should only be attempted *after* you have trained the top-level classifier with the pretrained model set to non-trainable**. If you add a randomly initialized classifier on top of a pretrained model and attempt to train all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier), and your pretrained model will just forget everything it has learned.\n",
        "- Additionally, we **fine-tune only the *top layers* of the pre-trained model** rather than all layers of the pretrained model because, in a convnet, the higher up a layer is, the more specialized it is. The first few layers in a convnet learn very simple and generic features, which generalize to almost all types of images. But as you go higher up, the features are increasingly specific to the dataset that the model is trained on. The goal of fine-tuning is to adapt these specialized features to work with the new dataset.\n",
        "\n",
        "All we need to do to implement fine-tuning is to set the top layers of Inception V3 to be trainable, recompile the model (necessary for these changes to take effect), and resume training. Let's unfreeze all layers belonging to the `mixed7` module—i.e., all layers found after `mixed6`—and recompile the model:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_l_J4S0Z2rgg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "unfreeze = False\n",
        "#-----------------------------------\n",
        "# Unfreeze all models after \"mixed6\"\n",
        "#-----------------------------------\n",
        "for layer in pre_trained_model.layers:\n",
        "  \n",
        "  if unfreeze              : layer.trainable = True\n",
        "  if layer.name == 'mixed6': unfreeze        = True\n",
        "\n",
        "# As an optimizer, here we will use SGD \n",
        "# with a very low learning rate (0.00001)\n",
        "\n",
        "model.compile( optimizer =   SGD(lr=0.00001,momentum=0.9), \n",
        "                    loss =  'binary_crossentropy'        ,\n",
        "                 metrics = ['acc']\n",
        "             )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zE37ARlqY9da"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's retrain the model. We'll train on all 2000 images available, for 50 epochs, and validate on all 1,000 test images. (This may take 15-20 minutes to run.)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "o_GgDGG4Y_hJ",
        "outputId": "d487ee90-2f1f-42b7-d91d-2bab54a1d4bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit_generator( train_generator                         ,\n",
        "                               validation_data  = validation_generator ,\n",
        "                               steps_per_epoch  = 100                  ,  # 2000 images = batch_size * steps\n",
        "                               epochs           =  2                  , ##--50\n",
        "                               validation_steps =  50                  ,  # 1000 images = batch_size * steps\n",
        "                               verbose          =   2                     # Verbosity mode (one line per epoch)\n",
        "                             )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "50/50 [==============================] - 7s 150ms/step - loss: 0.3372 - acc: 0.9230\n",
            " - 30s - loss: 0.3401 - acc: 0.8595 - val_loss: 0.3372 - val_acc: 0.9230\n",
            "Epoch 2/2\n",
            "50/50 [==============================] - 7s 132ms/step - loss: 0.3763 - acc: 0.9130\n",
            " - 27s - loss: 0.3144 - acc: 0.8655 - val_loss: 0.3763 - val_acc: 0.9130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3EPGn58ofwq5"
      },
      "cell_type": "markdown",
      "source": [
        "You should see that the accuracy continues to be very high. It might dip up and down, but hover around 96%. For reasons why it goes up and down explore readings on overfitting and underfitting and how gradient descent works. For the purpose of this course, I'm just focussing on the code :)\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1FtxcKjJfxL9",
        "outputId": "4d5745e5-576b-472b-bdda-eb06d5dddcde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "#------------------------------------------------------\n",
        "# Retrieve a list of  results on training and test data\n",
        "# sets for each training epoch\n",
        "#------------------------------------------------------\n",
        "acc      = history.history[      'acc' ]\n",
        "val_acc  = history.history[ ' val_acc' ]\n",
        "loss     = history.history[     'loss' ]\n",
        "val_loss = history.history[ 'val_loss' ]\n",
        "\n",
        "\n",
        "epochs = range(len(acc))  # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot ( epochs,     acc )\n",
        "plt.plot ( epochs, val_acc )\n",
        "plt.title( 'Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot ( epochs,     loss )\n",
        "plt.plot ( epochs, val_loss )\n",
        "plt.title( 'Training and validation loss')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,'Training and validation loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEHCAYAAABV4gY/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAIj77V4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEHCAYAAABV4gY/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrxHjXecZAzIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "X-fUIeizakjE"
      },
      "cell_type": "markdown",
      "source": [
        "Congratulations! Using feature extraction and fine-tuning, you've built an image classification model that can identify cats vs. dogs in images with over 90% accuracy."
      ]
    },
    {
      "metadata": {
        "id": "dgVrgjpTHGaL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "x_ANwJCnx7w-"
      },
      "cell_type": "markdown",
      "source": [
        "## Clean Up\n",
        "\n",
        "Run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-hUmyohAyBzh",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}